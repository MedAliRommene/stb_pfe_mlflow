{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\stb_pfe_mlflow\\\\research'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\stb_pfe_mlflow'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataCleaningConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stb_pfe_mlflow.constants import *\n",
    "from stb_pfe_mlflow.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "   \n",
    "    def get_data_cleaning_config(self) -> DataCleaningConfig:\n",
    "        config = self.config.data_cleaning\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_cleaning_config = DataCleaningConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_cleaning_config\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "\n",
    "from stb_pfe_mlflow import logger\n",
    "from stb_pfe_mlflow.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiers_key</th>\n",
       "      <th>ca</th>\n",
       "      <th>TOTMVTC</th>\n",
       "      <th>TOTMVTD</th>\n",
       "      <th>TOTMVTCnet</th>\n",
       "      <th>TOTMVTDnet</th>\n",
       "      <th>ENG</th>\n",
       "      <th>MontImp</th>\n",
       "      <th>encours</th>\n",
       "      <th>Encours_Moyen_Debiteur</th>\n",
       "      <th>...</th>\n",
       "      <th>Code_Classe</th>\n",
       "      <th>Var Signalitiques.Code_Profession</th>\n",
       "      <th>Var Signalitiques.Profession</th>\n",
       "      <th>Var Signalitiques.Code_Activite_Economique</th>\n",
       "      <th>Var Signalitiques.Activite_Economique</th>\n",
       "      <th>Var Signalitiques.Code_secteur_activite</th>\n",
       "      <th>Var Signalitiques.Secteur_Activite</th>\n",
       "      <th>Var Signalitiques.Ville</th>\n",
       "      <th>Var Signalitiques.Code_Postal</th>\n",
       "      <th>Var Signalitiques.Date_Ouverture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-274.956</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-261.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1420.500876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAB99</td>\n",
       "      <td>TRANSPORTS FERROVIAIRES DE FRET</td>\n",
       "      <td>HA</td>\n",
       "      <td>TRANSPORTS ET ENTREPOSAGE</td>\n",
       "      <td>BAB BHAR</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1958-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-483.776</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-450.691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.483331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCG99</td>\n",
       "      <td>AUTRES COMMERCES DE DETAIL DE BIENS NEUFS EN M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1992-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAA04</td>\n",
       "      <td>COMMERCE D'ELECTRICITE</td>\n",
       "      <td>DA</td>\n",
       "      <td>PRODUCTION ET DISTRIBUTION D'ELECTRICITE, DE G...</td>\n",
       "      <td>TUNIS BELVEDERE</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-362.465</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-341.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.732704</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CWA01</td>\n",
       "      <td>FABRICATION DE MEUBLES DE BUREAU ET DE MAGASIN</td>\n",
       "      <td>CW</td>\n",
       "      <td>INDUSTRIE MANUFACTURIERE</td>\n",
       "      <td>TUNIS BELVEDERE</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1992-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633</td>\n",
       "      <td>3171.408</td>\n",
       "      <td>3224.323</td>\n",
       "      <td>-7610.750</td>\n",
       "      <td>3224.323</td>\n",
       "      <td>-7610.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GBG05</td>\n",
       "      <td>COMMERCE DE GROS DE QUINCAILLERIE ET FOURNITUR...</td>\n",
       "      <td>GB</td>\n",
       "      <td>COMMERCE; REPARATION D'AUTOMOBILES ET DE MOTOC...</td>\n",
       "      <td>REPUBLIQUE</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1992-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tiers_key        ca   TOTMVTC   TOTMVTD  TOTMVTCnet  TOTMVTDnet  ENG  \\\n",
       "0        174       NaN     0.000  -274.956       0.000    -261.171  NaN   \n",
       "1        370       NaN     0.000  -483.776       0.000    -450.691  NaN   \n",
       "2        481       NaN       NaN       NaN         NaN         NaN  NaN   \n",
       "3        578       NaN     0.000  -362.465       0.000    -341.152  NaN   \n",
       "4        633  3171.408  3224.323 -7610.750    3224.323   -7610.750  NaN   \n",
       "\n",
       "   MontImp encours  Encours_Moyen_Debiteur  ...  Code_Classe  \\\n",
       "0      NaN     NaN             1420.500876  ...          1.0   \n",
       "1      NaN     NaN             2311.483331  ...          1.0   \n",
       "2      NaN     NaN                     NaN  ...          NaN   \n",
       "3      NaN     NaN             1500.732704  ...          NaN   \n",
       "4      NaN     NaN                     NaN  ...          NaN   \n",
       "\n",
       "   Var Signalitiques.Code_Profession  Var Signalitiques.Profession  \\\n",
       "0                                NaN                           NaN   \n",
       "1                                NaN                           NaN   \n",
       "2                                NaN                           NaN   \n",
       "3                                NaN                           NaN   \n",
       "4                                NaN                           NaN   \n",
       "\n",
       "   Var Signalitiques.Code_Activite_Economique  \\\n",
       "0                                       HAB99   \n",
       "1                                       GCG99   \n",
       "2                                       DAA04   \n",
       "3                                       CWA01   \n",
       "4                                       GBG05   \n",
       "\n",
       "               Var Signalitiques.Activite_Economique  \\\n",
       "0                    TRANSPORTS FERROVIAIRES DE FRET   \n",
       "1  AUTRES COMMERCES DE DETAIL DE BIENS NEUFS EN M...   \n",
       "2                             COMMERCE D'ELECTRICITE   \n",
       "3     FABRICATION DE MEUBLES DE BUREAU ET DE MAGASIN   \n",
       "4  COMMERCE DE GROS DE QUINCAILLERIE ET FOURNITUR...   \n",
       "\n",
       "  Var Signalitiques.Code_secteur_activite  \\\n",
       "0                                      HA   \n",
       "1                                     NaN   \n",
       "2                                      DA   \n",
       "3                                      CW   \n",
       "4                                      GB   \n",
       "\n",
       "                  Var Signalitiques.Secteur_Activite  Var Signalitiques.Ville  \\\n",
       "0                          TRANSPORTS ET ENTREPOSAGE                 BAB BHAR   \n",
       "1                                                NaN                    TUNIS   \n",
       "2  PRODUCTION ET DISTRIBUTION D'ELECTRICITE, DE G...          TUNIS BELVEDERE   \n",
       "3                           INDUSTRIE MANUFACTURIERE          TUNIS BELVEDERE   \n",
       "4  COMMERCE; REPARATION D'AUTOMOBILES ET DE MOTOC...               REPUBLIQUE   \n",
       "\n",
       "   Var Signalitiques.Code_Postal  Var Signalitiques.Date_Ouverture  \n",
       "0                         1000.0                        1958-04-05  \n",
       "1                         1002.0                        1992-04-14  \n",
       "2                         1002.0                        2000-01-01  \n",
       "3                         1002.0                        1992-05-07  \n",
       "4                         1001.0                        1992-02-20  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"artifacts/data_ingestion/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    def __init__(self, config: DataCleaningConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "    \n",
    "    def cleaning_data(self):\n",
    "        # Renommer les colonnes qui commencent par \"Var Signalitiques.\"\n",
    "        df.rename(columns=lambda x: x.replace(\"Var Signalitiques.\", \"\") if x.startswith(\"Var Signalitiques.\") else x, inplace=True)\n",
    "    \n",
    "        # Suppression des colonnes spécifiées\n",
    "        columns_to_drop = [\n",
    "        'INCIDENTCHQ_R', 'INCIDENTCHQ_N_R', 'INCIDENTCHQ', 'NBIMP',\n",
    "        'Interdit', 'InterditAct', 'Interet_Non_ECHU', 'Encaiss_Recu', 'Code_Postal'\n",
    "        ]\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Remplir les valeurs manquantes dans les colonnes numériques avec la médiane ou la moyenne\n",
    "        df['ca'].fillna(df['ca'].median(), inplace=True)\n",
    "        df['TOTMVTC'].fillna(df['TOTMVTC'].mean(), inplace=True)\n",
    "        df['TOTMVTD'].fillna(df['TOTMVTD'].mean(), inplace=True)\n",
    "        df['TOTMVTCnet'].fillna(df['TOTMVTCnet'].mean(), inplace=True)\n",
    "        df['TOTMVTDnet'].fillna(df['TOTMVTDnet'].mean(), inplace=True)\n",
    "    \n",
    "        # Assurer que TOTMVTC et TOTMVTCnet soient toujours positifs\n",
    "        df['TOTMVTC'] = df['TOTMVTC'].abs()  # Convertir en valeur absolue pour s'assurer qu'il est positif\n",
    "        df['TOTMVTCnet'] = df['TOTMVTCnet'].abs()  # Convertir en valeur absolue pour s'assurer qu'il est positif\n",
    "    \n",
    "        # Assurer que TOTMVTD et TOTMVTDnet soient toujours négatifs\n",
    "        df['TOTMVTD'] = -df['TOTMVTD'].abs()  # Convertir en valeur absolue et rendre négatif\n",
    "        df['TOTMVTDnet'] = -df['TOTMVTDnet'].abs()  # Convertir en valeur absolue et rendre négatif\n",
    "    \n",
    "        # Limiter le nombre de décimales à 2 pour une meilleure lisibilité\n",
    "        df['TOTMVTC'] = df['TOTMVTC'].round(2)\n",
    "        df['TOTMVTCnet'] = df['TOTMVTCnet'].round(2)\n",
    "        df['TOTMVTD'] = df['TOTMVTD'].round(2)\n",
    "        df['TOTMVTDnet'] = df['TOTMVTDnet'].round(2)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'ENG' par 0 (ou \"Non\")\n",
    "        df['ENG'].fillna(0, inplace=True)  # Ici, on suppose que \"0\" représente une catégorie manquante\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'MontImp' par 0\n",
    "        df['MontImp'].fillna(0, inplace=True)\n",
    "    \n",
    "        # Conversion de la colonne 'encours' en numérique (et gestion des erreurs de conversion)\n",
    "        df['encours'] = pd.to_numeric(df['encours'], errors='coerce')\n",
    "    \n",
    "        # Vérification du nombre de valeurs NaN dans 'encours'\n",
    "        print(df['encours'].isna().sum())\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'encours' avec la médiane\n",
    "        df['encours'].fillna(df['encours'].median(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans d'autres colonnes numériques avec la médiane\n",
    "        df['Encours_Moyen_Debiteur'].fillna(df['Encours_Moyen_Debiteur'].median(), inplace=True)\n",
    "        df['Encours_Moyen_crediteur'].fillna(df['Encours_Moyen_crediteur'].median(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'NBECHEANCE' avec la moyenne\n",
    "        df['NBECHEANCE'].fillna(df['NBECHEANCE'].mean(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'Code_Classe' avec la valeur la plus fréquente (mode)\n",
    "        df['Code_Classe'].fillna(df['Code_Classe'].mode()[0], inplace=True)\n",
    "\n",
    "        # Remplir les valeurs manquantes dans certaines colonnes catégorielles avec la valeur la plus fréquente\n",
    "        categorical_columns = ['Profession', 'Code_Profession', 'Secteur_Activite', 'Code_secteur_activite', \n",
    "                           'Activite_Economique', 'Code_Activite_Economique', 'Ville']\n",
    "    \n",
    "        for col in categorical_columns:\n",
    "            if col in df.columns:  # Vérifie si la colonne existe dans le DataFrame\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            else:\n",
    "                print(f\"Colonne '{col}' non trouvée dans le DataFrame.\")\n",
    "\n",
    "        # Assurez-vous que la colonne 'Date_Ouverture' est au format datetime\n",
    "        df['Date_Ouverture'] = pd.to_datetime(df['Date_Ouverture'], errors='coerce')\n",
    "    \n",
    "        # Imputation des valeurs manquantes dans 'Date_Ouverture' avec la date médiane\n",
    "        median_date = df['Date_Ouverture'].median()\n",
    "        df['Date_Ouverture'].fillna(median_date, inplace=True)\n",
    "    \n",
    "        # Fonction pour calculer le nombre d'années écoulées depuis la date d'ouverture\n",
    "        def calculate_years_since(date):\n",
    "            today = pd.Timestamp.today()\n",
    "            return today.year - date.year - ((today.month, today.day) < (date.month, date.day))\n",
    "    \n",
    "        # Appliquer la fonction pour créer une nouvelle colonne 'ancienneté' (en années)\n",
    "        df['ancienneté'] = df['Date_Ouverture'].apply(calculate_years_since)\n",
    "    \n",
    "        # Afficher les premières lignes pour vérifier la transformation\n",
    "        # print(df[['Date_Ouverture', 'ancienneté', 'TOTMVTC', 'TOTMVTD', 'TOTMVTCnet', 'TOTMVTDnet']].head())\n",
    "    \n",
    "        df.to_csv(os.path.join(self.config.root_dir, \"clean_data.csv\"),index = False)\n",
    "        logger.info(\"Cleaning the data\")\n",
    "        logger.info(df.shape)\n",
    "        \n",
    "   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-10 01:39:47,562: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,563: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,567: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,568: INFO: common: created directory at: artifacts]\n",
      "[2024-09-10 01:39:47,570: INFO: common: created directory at: artifacts/data_cleaning]\n",
      "11457\n",
      "[2024-09-10 01:39:47,796: INFO: 3365399240: Cleaning the data]\n",
      "[2024-09-10 01:39:47,798: INFO: 3365399240: (12946, 22)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_cleaning_config = config.get_data_cleaning_config()\n",
    "    data_cleaning = DataCleaning(config=data_cleaning_config)\n",
    "    data_cleaning.cleaning_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
