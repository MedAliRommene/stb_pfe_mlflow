{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\stb_pfe_mlflow\\\\research'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\stb_pfe_mlflow'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataCleaningConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stb_pfe_mlflow.constants import *\n",
    "from stb_pfe_mlflow.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "   \n",
    "    def get_data_cleaning_config(self) -> DataCleaningConfig:\n",
    "        config = self.config.data_cleaning\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_cleaning_config = DataCleaningConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_cleaning_config\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "\n",
    "from stb_pfe_mlflow import logger\n",
    "from stb_pfe_mlflow.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiers_key</th>\n",
       "      <th>ca</th>\n",
       "      <th>TOTMVTC</th>\n",
       "      <th>TOTMVTD</th>\n",
       "      <th>TOTMVTCnet</th>\n",
       "      <th>TOTMVTDnet</th>\n",
       "      <th>ENG</th>\n",
       "      <th>MontImp</th>\n",
       "      <th>encours</th>\n",
       "      <th>Encours_Moyen_Debiteur</th>\n",
       "      <th>...</th>\n",
       "      <th>Code_Classe</th>\n",
       "      <th>Var Signalitiques.Code_Profession</th>\n",
       "      <th>Var Signalitiques.Profession</th>\n",
       "      <th>Var Signalitiques.Code_Activite_Economique</th>\n",
       "      <th>Var Signalitiques.Activite_Economique</th>\n",
       "      <th>Var Signalitiques.Code_secteur_activite</th>\n",
       "      <th>Var Signalitiques.Secteur_Activite</th>\n",
       "      <th>Var Signalitiques.Ville</th>\n",
       "      <th>Var Signalitiques.Code_Postal</th>\n",
       "      <th>Var Signalitiques.Date_Ouverture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-274.956</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-261.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1420.500876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAB99</td>\n",
       "      <td>TRANSPORTS FERROVIAIRES DE FRET</td>\n",
       "      <td>HA</td>\n",
       "      <td>TRANSPORTS ET ENTREPOSAGE</td>\n",
       "      <td>BAB BHAR</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1958-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-483.776</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-450.691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.483331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCG99</td>\n",
       "      <td>AUTRES COMMERCES DE DETAIL DE BIENS NEUFS EN M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1992-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAA04</td>\n",
       "      <td>COMMERCE D'ELECTRICITE</td>\n",
       "      <td>DA</td>\n",
       "      <td>PRODUCTION ET DISTRIBUTION D'ELECTRICITE, DE G...</td>\n",
       "      <td>TUNIS BELVEDERE</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-362.465</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-341.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.732704</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CWA01</td>\n",
       "      <td>FABRICATION DE MEUBLES DE BUREAU ET DE MAGASIN</td>\n",
       "      <td>CW</td>\n",
       "      <td>INDUSTRIE MANUFACTURIERE</td>\n",
       "      <td>TUNIS BELVEDERE</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1992-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633</td>\n",
       "      <td>3171.408</td>\n",
       "      <td>3224.323</td>\n",
       "      <td>-7610.750</td>\n",
       "      <td>3224.323</td>\n",
       "      <td>-7610.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GBG05</td>\n",
       "      <td>COMMERCE DE GROS DE QUINCAILLERIE ET FOURNITUR...</td>\n",
       "      <td>GB</td>\n",
       "      <td>COMMERCE; REPARATION D'AUTOMOBILES ET DE MOTOC...</td>\n",
       "      <td>REPUBLIQUE</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1992-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tiers_key        ca   TOTMVTC   TOTMVTD  TOTMVTCnet  TOTMVTDnet  ENG  \\\n",
       "0        174       NaN     0.000  -274.956       0.000    -261.171  NaN   \n",
       "1        370       NaN     0.000  -483.776       0.000    -450.691  NaN   \n",
       "2        481       NaN       NaN       NaN         NaN         NaN  NaN   \n",
       "3        578       NaN     0.000  -362.465       0.000    -341.152  NaN   \n",
       "4        633  3171.408  3224.323 -7610.750    3224.323   -7610.750  NaN   \n",
       "\n",
       "   MontImp encours  Encours_Moyen_Debiteur  ...  Code_Classe  \\\n",
       "0      NaN     NaN             1420.500876  ...          1.0   \n",
       "1      NaN     NaN             2311.483331  ...          1.0   \n",
       "2      NaN     NaN                     NaN  ...          NaN   \n",
       "3      NaN     NaN             1500.732704  ...          NaN   \n",
       "4      NaN     NaN                     NaN  ...          NaN   \n",
       "\n",
       "   Var Signalitiques.Code_Profession  Var Signalitiques.Profession  \\\n",
       "0                                NaN                           NaN   \n",
       "1                                NaN                           NaN   \n",
       "2                                NaN                           NaN   \n",
       "3                                NaN                           NaN   \n",
       "4                                NaN                           NaN   \n",
       "\n",
       "   Var Signalitiques.Code_Activite_Economique  \\\n",
       "0                                       HAB99   \n",
       "1                                       GCG99   \n",
       "2                                       DAA04   \n",
       "3                                       CWA01   \n",
       "4                                       GBG05   \n",
       "\n",
       "               Var Signalitiques.Activite_Economique  \\\n",
       "0                    TRANSPORTS FERROVIAIRES DE FRET   \n",
       "1  AUTRES COMMERCES DE DETAIL DE BIENS NEUFS EN M...   \n",
       "2                             COMMERCE D'ELECTRICITE   \n",
       "3     FABRICATION DE MEUBLES DE BUREAU ET DE MAGASIN   \n",
       "4  COMMERCE DE GROS DE QUINCAILLERIE ET FOURNITUR...   \n",
       "\n",
       "  Var Signalitiques.Code_secteur_activite  \\\n",
       "0                                      HA   \n",
       "1                                     NaN   \n",
       "2                                      DA   \n",
       "3                                      CW   \n",
       "4                                      GB   \n",
       "\n",
       "                  Var Signalitiques.Secteur_Activite  Var Signalitiques.Ville  \\\n",
       "0                          TRANSPORTS ET ENTREPOSAGE                 BAB BHAR   \n",
       "1                                                NaN                    TUNIS   \n",
       "2  PRODUCTION ET DISTRIBUTION D'ELECTRICITE, DE G...          TUNIS BELVEDERE   \n",
       "3                           INDUSTRIE MANUFACTURIERE          TUNIS BELVEDERE   \n",
       "4  COMMERCE; REPARATION D'AUTOMOBILES ET DE MOTOC...               REPUBLIQUE   \n",
       "\n",
       "   Var Signalitiques.Code_Postal  Var Signalitiques.Date_Ouverture  \n",
       "0                         1000.0                        1958-04-05  \n",
       "1                         1002.0                        1992-04-14  \n",
       "2                         1002.0                        2000-01-01  \n",
       "3                         1002.0                        1992-05-07  \n",
       "4                         1001.0                        1992-02-20  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"artifacts/data_ingestion/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    def __init__(self, config: DataCleaningConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "    \n",
    "    def cleaning_data(self):\n",
    "        # Renommer les colonnes qui commencent par \"Var Signalitiques.\"\n",
    "        df.rename(columns=lambda x: x.replace(\"Var Signalitiques.\", \"\") if x.startswith(\"Var Signalitiques.\") else x, inplace=True)\n",
    "    \n",
    "        # Suppression des colonnes spÃ©cifiÃ©es\n",
    "        columns_to_drop = [\n",
    "        'INCIDENTCHQ_R', 'INCIDENTCHQ_N_R', 'INCIDENTCHQ', 'NBIMP',\n",
    "        'Interdit', 'InterditAct', 'Interet_Non_ECHU', 'Encaiss_Recu', 'Code_Postal'\n",
    "        ]\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Remplir les valeurs manquantes dans les colonnes numÃ©riques avec la mÃ©diane ou la moyenne\n",
    "        df['ca'].fillna(df['ca'].median(), inplace=True)\n",
    "        df['TOTMVTC'].fillna(df['TOTMVTC'].mean(), inplace=True)\n",
    "        df['TOTMVTD'].fillna(df['TOTMVTD'].mean(), inplace=True)\n",
    "        df['TOTMVTCnet'].fillna(df['TOTMVTCnet'].mean(), inplace=True)\n",
    "        df['TOTMVTDnet'].fillna(df['TOTMVTDnet'].mean(), inplace=True)\n",
    "    \n",
    "        # Assurer que TOTMVTC et TOTMVTCnet soient toujours positifs\n",
    "        df['TOTMVTC'] = df['TOTMVTC'].abs()  # Convertir en valeur absolue pour s'assurer qu'il est positif\n",
    "        df['TOTMVTCnet'] = df['TOTMVTCnet'].abs()  # Convertir en valeur absolue pour s'assurer qu'il est positif\n",
    "    \n",
    "        # Assurer que TOTMVTD et TOTMVTDnet soient toujours nÃ©gatifs\n",
    "        df['TOTMVTD'] = -df['TOTMVTD'].abs()  # Convertir en valeur absolue et rendre nÃ©gatif\n",
    "        df['TOTMVTDnet'] = -df['TOTMVTDnet'].abs()  # Convertir en valeur absolue et rendre nÃ©gatif\n",
    "    \n",
    "        # Limiter le nombre de dÃ©cimales Ã  2 pour une meilleure lisibilitÃ©\n",
    "        df['TOTMVTC'] = df['TOTMVTC'].round(2)\n",
    "        df['TOTMVTCnet'] = df['TOTMVTCnet'].round(2)\n",
    "        df['TOTMVTD'] = df['TOTMVTD'].round(2)\n",
    "        df['TOTMVTDnet'] = df['TOTMVTDnet'].round(2)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'ENG' par 0 (ou \"Non\")\n",
    "        df['ENG'].fillna(0, inplace=True)  # Ici, on suppose que \"0\" reprÃ©sente une catÃ©gorie manquante\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'MontImp' par 0\n",
    "        df['MontImp'].fillna(0, inplace=True)\n",
    "    \n",
    "        # Conversion de la colonne 'encours' en numÃ©rique (et gestion des erreurs de conversion)\n",
    "        df['encours'] = pd.to_numeric(df['encours'], errors='coerce')\n",
    "    \n",
    "        # VÃ©rification du nombre de valeurs NaN dans 'encours'\n",
    "        print(df['encours'].isna().sum())\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'encours' avec la mÃ©diane\n",
    "        df['encours'].fillna(df['encours'].median(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans d'autres colonnes numÃ©riques avec la mÃ©diane\n",
    "        df['Encours_Moyen_Debiteur'].fillna(df['Encours_Moyen_Debiteur'].median(), inplace=True)\n",
    "        df['Encours_Moyen_crediteur'].fillna(df['Encours_Moyen_crediteur'].median(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'NBECHEANCE' avec la moyenne\n",
    "        df['NBECHEANCE'].fillna(df['NBECHEANCE'].mean(), inplace=True)\n",
    "    \n",
    "        # Remplir les valeurs manquantes dans 'Code_Classe' avec la valeur la plus frÃ©quente (mode)\n",
    "        df['Code_Classe'].fillna(df['Code_Classe'].mode()[0], inplace=True)\n",
    "\n",
    "        # Remplir les valeurs manquantes dans certaines colonnes catÃ©gorielles avec la valeur la plus frÃ©quente\n",
    "        categorical_columns = ['Profession', 'Code_Profession', 'Secteur_Activite', 'Code_secteur_activite', \n",
    "                           'Activite_Economique', 'Code_Activite_Economique', 'Ville']\n",
    "    \n",
    "        for col in categorical_columns:\n",
    "            if col in df.columns:  # VÃ©rifie si la colonne existe dans le DataFrame\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            else:\n",
    "                print(f\"Colonne '{col}' non trouvÃ©e dans le DataFrame.\")\n",
    "\n",
    "        # Assurez-vous que la colonne 'Date_Ouverture' est au format datetime\n",
    "        df['Date_Ouverture'] = pd.to_datetime(df['Date_Ouverture'], errors='coerce')\n",
    "    \n",
    "        # Imputation des valeurs manquantes dans 'Date_Ouverture' avec la date mÃ©diane\n",
    "        median_date = df['Date_Ouverture'].median()\n",
    "        df['Date_Ouverture'].fillna(median_date, inplace=True)\n",
    "    \n",
    "        # Fonction pour calculer le nombre d'annÃ©es Ã©coulÃ©es depuis la date d'ouverture\n",
    "        def calculate_years_since(date):\n",
    "            today = pd.Timestamp.today()\n",
    "            return today.year - date.year - ((today.month, today.day) < (date.month, date.day))\n",
    "    \n",
    "        # Appliquer la fonction pour crÃ©er une nouvelle colonne 'anciennetÃ©' (en annÃ©es)\n",
    "        df['anciennetÃ©'] = df['Date_Ouverture'].apply(calculate_years_since)\n",
    "    \n",
    "        # Afficher les premiÃ¨res lignes pour vÃ©rifier la transformation\n",
    "        # print(df[['Date_Ouverture', 'anciennetÃ©', 'TOTMVTC', 'TOTMVTD', 'TOTMVTCnet', 'TOTMVTDnet']].head())\n",
    "    \n",
    "        df.to_csv(os.path.join(self.config.root_dir, \"clean_data.csv\"),index = False)\n",
    "        logger.info(\"Cleaning the data\")\n",
    "        logger.info(df.shape)\n",
    "        \n",
    "   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-10 01:39:47,562: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,563: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,567: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-09-10 01:39:47,568: INFO: common: created directory at: artifacts]\n",
      "[2024-09-10 01:39:47,570: INFO: common: created directory at: artifacts/data_cleaning]\n",
      "11457\n",
      "[2024-09-10 01:39:47,796: INFO: 3365399240: Cleaning the data]\n",
      "[2024-09-10 01:39:47,798: INFO: 3365399240: (12946, 22)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_cleaning_config = config.get_data_cleaning_config()\n",
    "    data_cleaning = DataCleaning(config=data_cleaning_config)\n",
    "    data_cleaning.cleaning_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
